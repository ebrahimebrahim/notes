{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scl(s,v):\n",
    "    \"\"\"return s*v where is a scalar and v is a sparse vector\"\"\"\n",
    "    return {key:s*val for key,val in v.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pretty': 1, 'bad': 1},\n",
       " {'good': 1, 'plot': 1},\n",
       " {'not': 1, 'good': 1},\n",
       " {'pretty': 1, 'scenery': 1}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [\n",
    "            \"pretty bad\",\n",
    "            \"good plot\",\n",
    "            \"not good\",\n",
    "            \"pretty scenery\",\n",
    "          ]\n",
    "\n",
    "def phi(review):\n",
    "    \"\"\"Returns sparse feature vector from review\"\"\"\n",
    "    return {word:1 for word in review.split()}\n",
    "\n",
    "xs = list(map(phi,reviews))\n",
    "ys = [-1.,1.,-1.,1.] # ground truth\n",
    "\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_hinge(x,y,w):\n",
    "    return max(0,1-y * util.dotProduct(w,x))\n",
    "\n",
    "def training_loss(xs,ys,w):\n",
    "    return np.array([loss_hinge(x,y,w) for x,y in zip(xs,ys)]).mean()\n",
    "\n",
    "def loss_hinge_grad(x,y,w):\n",
    "    if 1 - (y*util.dotProduct(w,x)) <= 0 : return 0\n",
    "    else: return scl(-y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: {}, training loss: 1.0\n",
      "w: {'pretty': -0.5, 'bad': -0.5}, training loss: 0.875\n",
      "w: {'pretty': -0.5, 'bad': -0.5, 'good': 0.5, 'plot': 0.5}, training loss: 0.75\n",
      "w: {'pretty': -0.5, 'bad': -0.5, 'good': 0.0, 'plot': 0.5, 'not': -0.5}, training loss: 0.625\n",
      "w: {'pretty': 0.0, 'bad': -0.5, 'good': 0.0, 'plot': 0.5, 'not': -0.5, 'scenery': 0.5}, training loss: 0.5\n"
     ]
    }
   ],
   "source": [
    "eta = 0.5\n",
    "w = {}\n",
    "for x,y in zip(xs,ys):\n",
    "    print(\"w: {}, training loss: {}\".format(w, training_loss(xs,ys,w)))\n",
    "    util.increment(w, -eta, loss_hinge_grad(x,y,w))\n",
    "print(\"w: {}, training loss: {}\".format(w, training_loss(xs,ys,w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That last vector is the answer to problem 1e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1f\n",
    "\n",
    "Suppose we had a dataset consisting of the reviews\n",
    "- $r_1 = $\"good\"\n",
    "- $r_2=$\"not good\"\n",
    "- $r_3=$\"bad\"\n",
    "- $r_4=$\"not bad\"\n",
    "\n",
    "The ground truth about these reviews is obvious: $[+1,-1,-1,+1]$\n",
    "(where $+1$ means it's a positive review and $-1$ means negative review).\n",
    "\n",
    "Then the feature space of word counts has dimension 3, if we say\n",
    "$$ \\phi([\\text{a review}]) = \n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "\\text{number of occurances of \"not\"}\\\\\n",
    "\\text{number of occurances of \"good\"}\\\\\n",
    "\\text{number of occurances of \"bad\"}\n",
    "\\end{array}\n",
    "\\right]$$\n",
    "\n",
    "**Claim:** It is impossible for a linear classifier to get zero error on the dataset above.\n",
    "\n",
    "_Proof:_ Suppose we had a linear classifier given by weight vector\n",
    "$w$, and that it gets zero error on the training set above. Remember that the prediction\n",
    "for input review $r$ would be $\\operatorname{sign}(w\\cdot\\phi(r))$.\n",
    "Then we'd have\n",
    "- $w_2 > 0$\n",
    "- $w_1 + w_2 < 0$\n",
    "- $w_3<0$\n",
    "- $w_1+w_3>0$\n",
    "\n",
    "From the first two we have\n",
    "$$ w_1 < -w_2 < 0, $$\n",
    "and from the last two we have\n",
    "$$ w_1 > -w_3 > 0, $$\n",
    "a contradiction. $\\square$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
